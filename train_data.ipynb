{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffb1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7006543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Flatten\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# One-hot encoding\n",
    "def one_hot(y):\n",
    "    onehot = np.zeros((y.size, 10))\n",
    "    onehot[np.arange(y.size), y] = 1\n",
    "    return onehot\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5861dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.randn(784, 128) * np.sqrt(2. / 784)\n",
    "    b1 = np.zeros((1, 128))\n",
    "\n",
    "    W2 = np.random.randn(128, 64) * np.sqrt(2. / 128)\n",
    "    b2 = np.zeros((1, 64))\n",
    "\n",
    "    W3 = np.random.randn(64, 10) * np.sqrt(2. / 64)\n",
    "    b3 = np.zeros((1, 10))\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa05a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    exp = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e7c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W1, b1, W2, b2, W3, b3):\n",
    "    Z1 = X @ W1 + b1\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    Z2 = A1 @ W2 + b2\n",
    "    A2 = relu(Z2)\n",
    "\n",
    "    Z3 = A2 @ W3 + b3\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    return Z1, A1, Z2, A2, Z3, A3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70be03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    loss = -np.sum(y_true * np.log(y_pred + 1e-8)) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ea5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, y, Z1, A1, Z2, A2, A3, W2, W3):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    dZ3 = A3 - y\n",
    "    dW3 = A2.T @ dZ3 / m\n",
    "    db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
    "\n",
    "    dA2 = dZ3 @ W3.T\n",
    "    dZ2 = dA2 * relu_derivative(Z2)\n",
    "    dW2 = A1.T @ dZ2 / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "    dA1 = dZ2 @ W2.T\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = X.T @ dZ1 / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    return dW1, db1, dW2, db2, dW3, db3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e650c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params, grads, lr):\n",
    "    for i in range(len(params)):\n",
    "        params[i] -= lr * grads[i]\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "040acd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs=20, lr=0.01, batch_size=64):\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3 = init_params()\n",
    "    m = X.shape[0]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Shuffle dataset\n",
    "        perm = np.random.permutation(m)\n",
    "        X_shuffled = X[perm]\n",
    "        y_shuffled = y[perm]\n",
    "\n",
    "        for i in range(0, m, batch_size):\n",
    "\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "\n",
    "            Z1, A1, Z2, A2, Z3, A3 = forward(\n",
    "                X_batch, W1, b1, W2, b2, W3, b3\n",
    "            )\n",
    "\n",
    "            grads = backward(\n",
    "                X_batch, y_batch,\n",
    "                Z1, A1, Z2, A2, A3,\n",
    "                W2, W3\n",
    "            )\n",
    "\n",
    "            params = [W1, b1, W2, b2, W3, b3]\n",
    "            params = update(params, grads, lr)\n",
    "\n",
    "            W1, b1, W2, b2, W3, b3 = params\n",
    "\n",
    "        # Evaluate loss after each epoch\n",
    "        _, _, _, _, _, A3_full = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "        loss = compute_loss(y, A3_full)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a1a0811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3914\n",
      "Epoch 2, Loss: 0.3027\n",
      "Epoch 3, Loss: 0.2647\n",
      "Epoch 4, Loss: 0.2400\n",
      "Epoch 5, Loss: 0.2161\n",
      "Epoch 6, Loss: 0.2011\n",
      "Epoch 7, Loss: 0.1856\n",
      "Epoch 8, Loss: 0.1753\n",
      "Epoch 9, Loss: 0.1635\n",
      "Epoch 10, Loss: 0.1547\n",
      "Epoch 11, Loss: 0.1472\n",
      "Epoch 12, Loss: 0.1402\n",
      "Epoch 13, Loss: 0.1317\n",
      "Epoch 14, Loss: 0.1252\n",
      "Epoch 15, Loss: 0.1202\n",
      "Epoch 16, Loss: 0.1151\n",
      "Epoch 17, Loss: 0.1126\n",
      "Epoch 18, Loss: 0.1068\n",
      "Epoch 19, Loss: 0.1012\n",
      "Epoch 20, Loss: 0.1005\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e876649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "def accuracy(X, y):\n",
    "    _, _, _, _, _, A3 = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "    predictions = np.argmax(A3, axis=1)\n",
    "    labels = np.argmax(y, axis=1)\n",
    "    return np.mean(predictions == labels)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f866e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "np.savez(\"model_weights.npz\",\n",
    "         W1=W1, b1=b1,\n",
    "         W2=W2, b2=b2,\n",
    "         W3=W3, b3=b3)\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
